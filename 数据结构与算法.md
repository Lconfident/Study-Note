# 第Ⅰ部分 到底什么是算法？

**计算机没什么用，他们只会告诉你答案。——巴勃罗·毕加索**

计算机科学的本质之一就是算法研究。利用计算机解决实际问题，首先会选择一个合适的数学模型，来抽象出问题的本质特征，然后就是寻找一种算法，作为问题的解法。用什么方法来设计算法，如何判定一个算法的性能，设计的算法用云少运行时间和存储内存，这些问题是设计软件时所必须考虑的。算法性能的好坏也直接影响到软件性能的优劣。

**什么是算法？**

通俗而言，算法就是一组完成任务的指令。

**算法有什么特征？**

1. 输入（Input）
2. 输出（Output）：一个算法必须有输出，不然没有什么意义来设计算法
3. 确定性（Definiteness）：每个步骤是明确定义的
4. 可行性（Effectiveness）
5. 有穷性（Finiteness）：执行有限步骤就终止

**算法有什么基本要素？**

- 对数据对象的运算和操作
> 算术运算、逻辑运算、关系运算和数据传输
- 算法的控制结构
> 顺序、选择和循环

算法可以用自然语言、流程图、N-S流程图和伪代码描述

**Data Structures + Algorithms  = Programs. ——Niklaus Wirth（1984年度图灵奖得主）**

**要怎样看待一个算法的好坏？**

​	这里提一下二分查找，其输入是有序的元素列表，如果要找的元素包含在列表中，二分查找返回其位置；否则返回null

> 这里的示例说明了二分查找的工作原理。我随便想一个1~100的数字。
> 你的目标是以最少的次数找到我的数字。你每次猜测后，我会说小了、大了或对了。
>
> 假如你从1开始依次往上猜，猜测的过程会很长很长，这就是简单查找，更准确的说法是傻找。每次都只能排除一个数字。如果我想的是99，你得猜99次才能猜到！
>
> 下面就是一种更好的猜法。从50开始猜，小了，但排除了一半的数字，至此，你知道1~50都小了。接下来，你猜75，大了，那余下的数字又排除了一半！再接下来，你猜63（50和75中间的数字）...这就是二分查找。不管我心里想的是哪个数字，你在7次之内都可以猜到，因为每次猜测都能排除很多数字！
>
> 一般来说，对于包含有n个元素的列表，用二分查找最多需要log<sub>2</sub><sup>n</sup>步，而简单查找却最多需要n步。

​	每次介绍算法时，我们都将讨论其运行时间。一般来说，应选择**效率**最高的算法，以最大限度地减少运行时间或占用空间。（有兴趣可看邓俊辉老师的[解释](https://www.bilibili.com/video/BV1hJ411S7wU?p=4&vd_source=4fe602163e123a42d52b1a7672e94c9a)）

​	回到之前的二分查找，使用它究竟可以节省多少时间呢？简单逐个地检查数字，如果列表有100个数字，最多需要猜100次。如果列表有40亿个数字，最多需要猜40亿次。换言之，最多需要猜测的次数与列表长度相同，这被称为**线性时间（linear time）**。

​	二分查找则不同，如果列表有100个数字，最多需要猜7次；如果列表有40亿个数字，最多需要猜32次。厉害吧？二分查找的运行时间为对数时间或（log时间）

​	运行时间是算法的尺子，那尺子上的刻度就是**大O表示法**，指出了算法究竟有多快。

> 上界（大 O 记号）、下界（Ω 记号）或者 准确界（ↀ 记号）三种表示方法
>
> O(1)<O(log<sub>2</sub><sup>n</sup>)<O(n)<O(n*log<sub>2</sub><sup>n</sup>)<O(n<sup>2</sup>)<O(n<sup>3</sup>)
> O(2<sup>n</sup>)<O(n!)<O(n<sup>n</sup>)

**算法的运行时间以不同的速度增加**

​	Tom要为NASA编写一个查找算法，这个算法要在火箭即将登陆火星前开始执行，帮助计算着陆点。这个示例表明，两种算法的运行时间呈现不同的增速。Tom需要做出决定，是使用二分查找还是简单查找。使用的算法必须快速而准确。一方面，二分查找速度更快，Tom必须在10s之内找到着陆地点，否则火箭将偏离方向。另一方面，简答查找编写起来更容易，因此出现Bug的可能性更小。Tom不希望关键时刻掉链子！为了确保万无一失，他决定计算两种算法在列表有100个元素的情况下各自需要的时间。

​	假设检查一个元素需要1毫秒。使用简单查找时，Tom必须查找100个元素，也就是需要100ms才能查找完毕。而使用二分查找时，只需检查7个元素（log<sub>2</sub><sup>100</sup>大约为7），因此需要7ms就能查找完毕。然而，实际要查找的列表有10亿个元素，这种情况下，Tom测试了一下二分查找，运行时间为30ms。他心想，二分查找的速度大约为简单查找的15倍，因为列表包含100个元素时，简单查找需要100ms，二分查找需要7ms。因此，列表包含10亿个元素时，简单查找需要30*15=450ms，完全符合在10s内查找完毕的要求。Tom决定使用简单查找，这真的是个正确的选择吗？

​	不是。实际上，Tom错了，而且错得十分离谱。列表包含10亿个元素时，简单查找需要10亿ms，相当于11天！为什么呢？因为**二分查找和简单查找的运行时间的增速不同。**也就是说，随着元素数量的增加，二分查找需要的额外时间并不多，而简单查找需要的额外时间却很多。Tom以为二分查找是简单查找的15倍，这不对：列表包含10亿个元素时，为3300万倍。有鉴于此，仅知道算法需要多长时间才能运行完还不够，还需要知道运行时间如何随列表增长而增加。这就是大名鼎鼎的**渐进分析法**。大O表示法指出了算法有多快。简答查找是O(n)。单位秒呢？没有——大O表达法**让你比较操作数，它指出了算法运行时间的增速**。

**大O表示法指出了最糟糕情况下的运行时间**

​	假设你试图用简单查找在电话簿上的人。你知道，简单查找的运行时间为O(n)，这意味着最糟糕情况下，必须查找每个条目。如果查找的认识Alen——电话簿里的第一个人，一次就能找到，无需查看每个条目。考虑到一次就找到Alen，请问这种算法的运行时间是O(n)还是O(1)呢？

​	简单查找的运行时间总是O(n)。查找Alen时，一次就找到了，这是最佳情况，但大O表示法说的是最糟糕的情形。在最糟糕的情形下，必须查看电话簿的每个条目，对应的运行时间为O(n)。这是一个保证——你知道简单查找运行时间不可能超过O(n)。

> 一些常见的大O运行时间
>
> 下面从快到慢列出经常遇到的5种大O运行时间
>
> - O(log<sub>2</sub><sup>n</sup>)，也叫对数时间，包括二分查找
> - O(n)，也叫线性时间，包括简单查找
> - O(n*log<sub>2</sub><sup>n</sup>)，包括较快的快速排序
> - O(n<sup>2</sup>)，包括较慢的选择排序
> - O(n!)，包括旅行商问题——一种非常慢的算法

这里做一个小小的总结。

- 算法的速度并非时间，而是操作数的增速
- 谈论算法的速度时，我们说的时随着输入的增加，其运行时间将以什么样的速度增加
- 算法的运行时间用大O表示法表示
- O(log<sup>n</sup>)比O(n)快，当搜索的元素越多时，前者比后者快得越多
- 一般O(log<sup>n</sup>)是指以2为底的O(log<sub>2</sub><sup>n</sup>)

**常见问题**

问题是越来越多，算法也是越来越多，但它们都是由一些求解基本问题的基本算法组合而成，下面是一些基本问题

1. 排序问题：插入排序、选择排序、归并排序、桶排序...
2. 查找问题：顺序查找、二分法查找、哈希查找...
3. 图问题：深度优先算法、广度优先算法、最短路径算法...
4. 组合问题：计算领域最难的问题，旅行商问题是典型
5. 几何问题：凸包问题和最近点对问题是典型
6. 数值问题：求解方程组、定积分、函数最大值...
7. 其他常见问题：最大子段和问题、找钱问题、背包问题、多段最短路径问题、n皇后问题、假币问题、（字符）串处理问题

**算法设计**

首先明确一点，并不是所有的问题都有算法。有的问题研究可行，就有对应的算法；有些问题不能说明可行，就没有对应的算法，但不是说这类问题没有结果。

> 例如，猜想问题，有结果，然而截至目前还没有算法

算法分为**数值计算算法**和**非数值计算算法**

> 数值计算算法
>
> 顾名思义，主要用于科学计算，像什么解方程的根、求积分和建立数学模型等
>
> 1. 迭代法，求解方程近似根
> 2. 插值法
> 3. 差分法，求解微分方程的近似解
> 4. 归纳法
> 5. 递推法
> 6. 减半递推技术
> 7. 递归法
>
> 非数值计算算法
>
> 1. 穷举法
> 2. 分治算法，问题不断化为更小的问题
> 3. 贪心算法，最优解
> 4. 动态规划算法，用填表的方法保存计算的中间结果
> 5. 回溯算法，跳过大量无需测试的数据，快速得解
> 6. 分支限界算法

# 第Ⅱ部分 了解算法...

**旅行商**

​	阅读到这，你可能认为不可能存在运行时间按为O(n!)的算法。让我来证明你错了！这是一个计算机科学领域非常著名的旅行商问题，其计算时间增加得非常快，而那些非常聪明的人都认为它没有改进空间。

​	有一位旅行商。他需要前往5个城市。这位旅行商（姑且称之为Opus吧）要前往5个城市，同时要确保旅程最短，为此，可考虑前往城市的各种可能顺序。对于每种顺序，他都计算总旅程，再挑选出旅程最短的路线。5个城市有120次操作。涉及6个城市时，需要720次操作（有720种排列方式）。涉及7个城市时，需要5040次操作！推广一下，涉及n个城市时，需要执行n！（n的阶乘）次操作才能计算出结果。因此运行时间为O(n!)，即阶乘时间。除非涉及的城市很少，否则需要执行非常多的操作。如果涉及的城市数超过100，根本不能在合理的时间内计算出来——等你计算出结果来，太阳都没了。

​	这种算法很糟糕！Oups应使用别的算法，可他别无选择。这是计算科学领域亟待解决的问题之一。对于这个问题，目前还没有找到更快的算法，我们只能去找近似答案。

**内存的工作原理**

​	假如你要去看演出，需要将东西寄存。寄存处有一个柜子，柜子有很多抽屉。每个抽屉可以放一样东西，你有两样东西需要寄存，因此要了两个抽屉。你将两样东西存放在抽屉里。现在你就可以去看演出了！这大致就是计算机内存的工作原理。

​	计算机就像是很多抽屉的集合体，每个抽屉都有地址。需要将数据存储到内存时，你请求计算机提供存储空间，计算机给你一个存储地址。需要存储多项数据时，有两种基本方式——数组和链表。它们差别很大。

## 数组和链表

​	有时候，你需要在内存中存储一系列元素。假如你要编写一个管理代办事项的应用程序，为此需要将这些代事项存储到内存中。应使用数组还是链表呢？鉴于数组更容易掌握，我们先将待办事项存储到数组中。使用数组就意味着所有的待办事项在内存中都是相连的（紧靠在一起的）。

​	现在假设你要添加第4个待办事项，但是后面的那个抽屉放着别人的东西！这就像你与朋友去看电影，找到地方就坐后又来了一位朋友，但原来坐的地方没有空的位置，只能再找一个可坐的座位。在这种情况下，你要求计算机重新分配一块可以容纳4个代办事项的内存，再将所有的待办事项移到那里。

​	如果又来了一位朋友，而当前的地方也没有空位，你们就得再次转移！真的麻烦！同样，在数组中添加新元素也可能很麻烦。如果没有了空间，就得一刀内存的其他地方，因此添加新元素得速度会很慢。一种办法就是''预留座位"：也就是说当前只有3个待办事项，但是我请求计算机给10个待办事项的位置，以防需要添加待办事项，只要它不超过10个，就无需转移。这似乎是一个不错的措施，但你应该明白，它存在以下两个缺点：

- 你额外请求的位置可能根本用不到，这将浪费内存。你不用，别人也用不了。
- 待办事项超过10个后，你还得转移。

面对这种问题，可使用**链表**来解决

**链表**

- 链表中的每个元素可存储在内存的**任何地方**。
- 链表中的每个元素都存储了**下一个元素的地址**，从而使一系列随机的内存地址串在一起。

​	这就如同寻宝游戏。你前往第一个地址，那里有一张纸条写着"下一个元素的地址是123"。因此，你前往地址123，那里又有一张纸条，写着"下一个元素的地址是847"，以此类推。在链表中添加元素很容易：只需将其放入内存，并将其地址存到前一个元素中。

​	使用链表时，根本不需要移动元素。这还可避免另一个问题。假如你与五位朋友去看一部很火的电影。你们六个人想坐在一起，但看电影的人多，没有六个一起的座位。数组只能说"电影看不了"；而链表却说"我们六个分开坐"，因此，只要有足够的内存空间，就有能力为链表分配内存。链表的优势在于插入元素方面，那数组的优势又是什么呢？

**数组**

​	排行榜网站总是使用卑鄙的手段来增加页面浏览量。它们不在一个页面展示整个排行榜，而将排行榜的每项内容放在一个页面，并让你点击"next"来查看下一项内容。你必须点击9次，才能看到第一大反派是谁，这让网站可以在10个页面给中显示广告，这样真的很烦。如果整个排行榜都显示在一个页面中，浙江方便得多。这样，用户可单击人名来获得更详细得信息。

​	链表存在类似得问题。在需要读取最后一个元素时，你不能直接读取，因为你不知道它所处得地址，必须先访问元素#1，从中获取#2的地址，再访问#2并从中获取#3的地址，以此类推，知道访问到最后一个元素。需要同时读取所有元素，链表的效率很高：你读取第一个元素，根据其中的地址再去读取下一个元素，以此类推；但如果你需要跳跃，链表的效率真的很低。

​	数组与此不同你知道其中每个元素的地址。假如有一个数组，它包含五个元素，起始地址#1为00，那么元素#5的地址是多少呢？执行简单的数学运算得到：04.需要随机读取元素时，数组的效率很高，因为可迅速找到数组的任何元素。在链表中，元素并非靠在一起的，你无法迅速计算出第五个元素的内存地址，只能从头开始查找，直到访问到第四个元素。

> 数组的元素编号从0开始而不是1
>
> 元素的位置称为索引

|      | 数组 | 链表 |
| ---- | ---- | ---- |
| 读取 | O(1) | O(n) |
| 插入 | O(n) | O(1) |

> O(n) = 线性时间
> O(1) = 常量时间

**在中间插入**

​	假如你要让待办事项按日期排列。之前，你在清单末尾添加待办事项。但现在你要根据新增待办事项的日期将其插入到正确的位置。需要往中间插入元素时，数组和链表究竟哪个会更好？使用链表时，插入元素很简单，只需修改它前面的那个元素指向的地址。而使用数组时，则必须将后面的元素都向后移。如果没有足够的空间，还得将整个数组赋值到其他地方！因此，当需要插入中间元素时，链表显然是最好的选择。

**删除**

如果你要删除元素呢？链表也是更好的选择，因为只需修改前一个元素指向的地址即可。而使用数组时，删除元素后，必须将后面的元素都前移。不同于插入，删除元素总能成功。如果内存中没有足够的空间，插入操作可能会失败，但在任何情况下都能将元素删除。

|      | 数组 | 链表 |
| ---- | ---- | ---- |
| 读取 | O(1) | O(n) |
| 插入 | O(n) | O(1) |
| 删除 | O(n) | O(1) |

> 需要指出的是，仅当能够立即访问要删除的元素时，删除操作的运行时间才为O(1)。通常我们记录了链表的第一个元素和最后一个元素，因此此删除这些元素时运行时间为O(1)

总结一句：链表擅长插入和删除，数组更擅长随机访问

## 选择排序

假如你的计算机里有很多乐曲,对于每个乐队，你都记录了其作品被播放的次数。你要将这个列表播放次数从多到少的顺序排列，从而将你最喜欢的乐队排序。该如何操作呢？

​	一种办法是遍历这个列表，找出作品播放次数最多的乐队，并将该乐队添加到一个新列表中。再次这样做，找出播放次数第二多的乐队。一直做下去，你将得到一个有序列表。下面从计算机的角度出发，看看这需要多长时间。不要忘记，O(n)意味着查看列表中的每个元素一次。例如，对乐队列表进行简单查找时，意味着每个乐队都要查看一次。因此这种时间为O(n)的操作，你需要执行n次。需要的总时间为O(n*n)=O(n<sup>2</sup>)。

**需要检查的元素数越来越少**

​	随着排序的进行，每次需要检查的元素数在逐渐减少，最后一次只需要检查一个元素。既然如此，运行时间怎么还是O(n<sup>2</sup>)呢？这个问题问得好，这与大O表示法的常数有关。

​	你说得没错，并非每次都需要检查n个元素。第一次需要检查n个元素，但随后检查的元素依次为n-1,n-2,...,2和1.平均每次检查的元素数为1/2×n，因此运行时间为O(n×1/2×n)，但大O表示法关注的是趋势，直接省略诸如1/2这样的常熟，因此简单地写作O(n<sup>2</sup>)。

选择排序是一种灵巧的算法，但速度不是很快。快速排序是一种更快的排序算法，其运行时间为O(nlog<sup>n</sup>)，之后会介绍。

**示例代码**

将数组元素从小到大的顺序排列。

先编写一个用于找出数组中最小元素的函数。

```python
def findSamllest(arr):
    smallest = arr[0];#存储最小值
    smallest_index = 0;#存储最小元素的索引
    for i in range(1,len(arr)):
        if arr[i] < smallest:
        smallest = arr[i]
        smallest_index = i
    return smallest_index
```

现在用这个函数编写选择排序算法

```python
def selectionSort(arr):
    newArr = []
    for i in range (len(arr)):
        smallest = findSmallest(arr)#找出最小的元素，并添加到新数组
        newArr.append(arr.pop(samllest))
    return newArr
print selectionSort([5,3,6,2,10])
```



## 递归算法

>  递归算法是一种通过自身调用自身或间接调用自身来达到问题解决的算法。

​	假设你在祖母的阁楼中翻箱倒柜，发现了一个上锁的神秘手提箱。祖母告诉你，钥匙很可能在下面这个盒子里。这个盒子里有盒子，而盒子里又有盒子。钥匙就在某个盒子中。为了找到钥匙，你将使用什么算法？

​	下面是一种方法。

1. 创建一个盒子堆
2. 从盒子堆中取出一个盒子，在里面找
3. 如果找到的是盒子，就将其加入盒子堆中，以便以后查找
4. 如果找到钥匙，就大功告成
5. 回到第二步

​	下面是另一种方法。

1. 检查盒子里的每样东西
2. 如果是盒子，就回到第一步
3. 如果是钥匙，就大功告成

哪种方法更容易呢？第一种方法使用的是while循环：只要盒子堆不空，就从中取一个盒子，并在里面仔细查找。

```python
def look_for_key(main_box):
    pile = main_box.make_a_pile_to_look_though()#pile：堆
    while pile is not empty:
        box = pile.grab_a_box()#grab：抓取
        for item in box:
            if item.is_a_box():
                pile.append(item)
            elif item.is_a_key():
                print "found the key!"
```

第二种方法使用递归——自己调用自己。

```python
def look_for_key(box):
    for item in box:
        if item.is_a_box():
            look_for_key(item)#递归
        elif item.is_a_key():
            print "found the key!"
```

这两种方法的作用相同。

"如果使用循环，程序的性能可能更高；如果使用递归，程序可能更容易理解。如何选择要看什么对你来说更重要。"                ——Leigh Caldwell

递归的**基本思想**是把一个要求解的问题划分成多个规模更小的子问题，这些子问题应该与原问题保持同一类型，然后用同样的方法求解规模更小的子问题。

**极限条件和递归条件**

由于递归函数调用自己，因此编写这样的函数时很容易出错，进而导致无限循环。假如你要编写一个倒计时的函数：`>3...2...1`

简单总结，递归具有以下**三个特性**：

1. 问题能被划分成一个或多个结构相同、规模更小的问题。相邻两次重复之间有联系，通常较小问题的输出是较大问题的输入
2. 递归调用的次数有限
3. 有结束递归的条件。当达到限制条件是，能直接得解

求阶乘问题。

> 要求解 `n!` 
>
> 首先要转化问题`n! = n * (n-1)!`，求解`(n-1)!`
>
> 然后划分小问题 `(n-1)! = (n-1) * (n-2)!`,求解`(n-2)!`
>
> 有规律的递减，直到`1!`结束
>
> 当得到`n=1`的解之后，再返回来，不断处理
>
> 直到得到规模为`n`的问题的解为止
>
> 递归在实现时，自身调用自身，层层向下进行，而求解原问题的解时次序正好相反
>
> ![阶乘](https://github.com/Lconfident/Pictures/blob/main/%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3/%E9%98%B6%E4%B9%98%E9%80%92%E5%BD%92.png)

